{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d8186d",
   "metadata": {},
   "source": [
    "# Wordcloud for MAU webapp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb049c9",
   "metadata": {},
   "source": [
    "Join the strings about the attitude to agriecology to one, use stop words to exclude not significant words, and use wordcloud graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "624edd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "df = pd.read_csv('data.csv',sep=';').dropna(how = 'all') # Base de datos consolidada (1er y 2do encuentro)\n",
    "text = ' '.join(df['Relación con la agroecología']).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "970e6506",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = re.sub('amos ', 'ar ', text)\n",
    "text = new\n",
    "new = re.sub('ales ', 'al ', text)\n",
    "text = new\n",
    "new = re.sub('ales ', 'al ', text)\n",
    "text = new\n",
    "new = re.sub('oles ', 'ol ', text)\n",
    "text = new\n",
    "new = re.sub('bles ', 'ble ', text)\n",
    "text = new\n",
    "new = re.sub('rtas', 'rta', text)\n",
    "text = new\n",
    "new = re.sub('ntas ', 'nta ', text)\n",
    "text = new\n",
    "new = re.sub('llas', 'lla ', text)\n",
    "text = new\n",
    "new = re.sub('ños ', 'ño ', text)\n",
    "text = new\n",
    "new = re.sub('ores ', 'or ', text)\n",
    "text = new\n",
    "new = re.sub('eres ', 'er ', text)\n",
    "text = new\n",
    "new = re.sub('cos ', 'co ', text)\n",
    "text = new\n",
    "new = re.sub('ces ', 'ce ', text)\n",
    "text = new\n",
    "new = re.sub('ces ', 'ce ', text)\n",
    "text = new\n",
    "new = re.sub('sos ', 'so ', text)\n",
    "text = new\n",
    "new = re.sub('idos ', 'ido ', text)\n",
    "text = new\n",
    "new = re.sub('idas ', 'ida ', text)\n",
    "text = new\n",
    "new = re.sub('ios', 'io', text)\n",
    "text = new\n",
    "new = re.sub('arias', 'ario', text)\n",
    "text = new\n",
    "new = re.sub('arias', 'ario', text)\n",
    "text = new\n",
    "new = re.sub('sques', 'sque', text)\n",
    "text = new\n",
    "new = re.sub('rtos', 'rto', text)\n",
    "text = new\n",
    "new = re.sub('pado', 'par', text)\n",
    "text = new\n",
    "new = re.sub('días', 'día', text)\n",
    "text = new\n",
    "new = re.sub('comunidades', 'comunidad', text)\n",
    "text = new\n",
    "new = re.sub('mezclados', 'mezclado', text)\n",
    "text = new\n",
    "new = re.sub('aprendizajes', 'aprendizaje', text)\n",
    "text = new\n",
    "new = re.sub('técnicas', 'técnico', text)\n",
    "text = new\n",
    "new = re.sub('amiges', 'amigo', text)\n",
    "text = new\n",
    "new = re.sub('regenerativas', 'regenerativo', text)\n",
    "text = new\n",
    "new = re.sub('productos', 'producto', text)\n",
    "text = new\n",
    "new = re.sub('plagas', 'plaga', text)\n",
    "text = new\n",
    "new = re.sub('ajar', 'ajo', text)\n",
    "text = new\n",
    "new = re.sub('bana', 'bano', text)\n",
    "text = new\n",
    "new = re.sub('aria', 'ario', text)\n",
    "text = new\n",
    "new = re.sub('duos', 'duo', text)\n",
    "text = new\n",
    "new = re.sub('años', 'año', text)\n",
    "text = new\n",
    "new = re.sub('cias', 'cia', text)\n",
    "text = new\n",
    "new = re.sub('tivos', 'tivo', text)\n",
    "text = new\n",
    "new = re.sub('arbol', 'árbol', text)\n",
    "text = new\n",
    "new = re.sub('gunos', 'guno', text)\n",
    "text = new\n",
    "new = re.sub('intos', 'into', text)\n",
    "text = new\n",
    "new = re.sub('esoro', 'esorar', text)\n",
    "text = new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "008d23c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frequency = {}    \n",
    "match_pattern= re.findall(r'[a-zóíéáúüôñàîïý]{3,20}', text)\n",
    "\n",
    "for word in match_pattern:\n",
    "    count = frequency.get(word,0)\n",
    "    frequency[word] = count + 1\n",
    "\n",
    "all_words = len(text.split())\n",
    "\n",
    "frequency_list = frequency.keys()\n",
    "freq_dic = []\n",
    "\n",
    "exclusion_list = ['con','que','de','la','lo','una','uno','sin','etc','donde','info','hace','para','desde','soy','los','las','por','fue','fueron','algo','por','ser','mis','cada','era','ahí','fui','entre','esto','esta','así','mas','más','lxs','del'\\\n",
    "'tengo','través','san','vamos','angamos','del', 'par', 'fau', 'mst', 'nos', 'vez', 'unxs', 'cómo', 'como', 'hago', 'matta', 'usach', 'aucca', 'vamos','eres','par','mucho','todas','todos', 'domo','san','joaquin', 'estos','varios','varios','jgm'\\\n",
    "                'tres','dos','cuatro','luego','llevo','sobre','y','una', 'chica','chico','brasil','tenido','también', 'chile']\n",
    "\n",
    "for words in frequency_list:\n",
    "        if words not in exclusion_list:    #review the exclusions\n",
    "            freq_dic.append([words, frequency[words],round(100*frequency[words]/all_words,2)])\n",
    "            \n",
    "dff = pd.DataFrame(freq_dic, columns = ['word', 'ocurrence','share%'])\n",
    "dff = dff.sort_values(by=\"ocurrence\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a570ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = dff.set_index('word').reset_index().fillna(0)\n",
    "f = f.sort_values(by = 'share%', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06851e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "d = {w: f for w, f in zip(f['word'],f['share%'])}\n",
    "\n",
    "wordcloud = WordCloud(background_color='turquoise', colormap='inferno', prefer_horizontal=1)\n",
    "wordcloud.generate_from_frequencies(frequencies=d)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "#plt.title(\" Most frequent words in opened questions (Selection) \\n Main goals | Member screening methods \",fontsize=12, y =1.07, wrap=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "34a4277b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#notebook { padding-top:0px !important; } .container { width:100% !important; } .end_space { min-height:0px !important; } </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\n",
    "    '<style>'\n",
    "        '#notebook { padding-top:0px !important; } ' \n",
    "        '.container { width:100% !important; } '\n",
    "        '.end_space { min-height:0px !important; } '\n",
    "    '</style>'\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d1dc74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
